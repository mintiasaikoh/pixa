#!/usr/bin/env python3
"""
Pixaã§ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Hugging Faceã‹ã‚‰å¿…è¦ãªãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’äº‹å‰ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™
"""

import os
import sys
from pathlib import Path
from huggingface_hub import snapshot_download, hf_hub_download
import torch

# ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
MODELS_DIR = Path("models")
MODELS_DIR.mkdir(exist_ok=True)

# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆ
MODELS_TO_DOWNLOAD = [
    {
        "id": "runwayml/stable-diffusion-v1-5",
        "name": "Stable Diffusion v1.5ï¼ˆæ¨™æº–ï¼‰",
        "type": "full",
        "size": "~4GB"
    },
    {
        "id": "PublicPrompts/All-In-One-Pixel-Model", 
        "name": "All-In-One Pixel Modelï¼ˆæ¨å¥¨ï¼‰",
        "type": "full",
        "size": "~2GB"
    },
    {
        "id": "Onodofthenorth/SD_PixelArt_SpriteSheet_Generator",
        "name": "ã‚¹ãƒ—ãƒ©ã‚¤ãƒˆã‚·ãƒ¼ãƒˆç”Ÿæˆ",
        "type": "full", 
        "size": "~2GB"
    },
    {
        "id": "kohbanye/pixel-art-style",
        "name": "Pixel Art Style",
        "type": "full",
        "size": "~2GB"
    },
    {
        "id": "wavymulder/Analog-Diffusion",
        "name": "Analog Diffusionï¼ˆãƒ¬ãƒˆãƒ­é¢¨ï¼‰",
        "type": "full",
        "size": "~2GB"
    },
    {
        "id": "stabilityai/stable-diffusion-xl-base-1.0",
        "name": "SDXL Baseï¼ˆLoRAç”¨ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼‰",
        "type": "full",
        "size": "~7GB"
    },
    {
        "id": "nerijs/pixel-art-xl",
        "name": "Pixel Art XL LoRA",
        "type": "lora",
        "size": "~200MB"
    },
    {
        "id": "latent-consistency/lcm-lora-sdxl",
        "name": "LCM LoRAï¼ˆé«˜é€ŸåŒ–ç”¨ï¼‰",
        "type": "lora",
        "size": "~200MB"
    },
    {
        "id": "pixelparty/pixel-party-xl",
        "name": "Pixel Party XLï¼ˆUNetã®ã¿ï¼‰",
        "type": "unet",
        "size": "~5GB"
    }
]

def get_cache_dir():
    """Hugging Faceã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—"""
    cache_dir = os.environ.get('HF_HOME', os.path.expanduser('~/.cache/huggingface'))
    return cache_dir

def download_model(model_info):
    """ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    model_id = model_info["id"]
    model_name = model_info["name"]
    model_type = model_info["type"]
    model_size = model_info["size"]
    
    print(f"\n{'='*60}")
    print(f"ğŸ“¦ ãƒ¢ãƒ‡ãƒ«: {model_name}")
    print(f"   ID: {model_id}")
    print(f"   ã‚µã‚¤ã‚º: {model_size}")
    print(f"   ã‚¿ã‚¤ãƒ—: {model_type}")
    print(f"{'='*60}")
    
    try:
        cache_dir = get_cache_dir()
        
        if model_type == "lora":
            # LoRAãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            print("ğŸ”½ LoRAãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
            files = ["pytorch_lora_weights.safetensors", "pytorch_lora_weights.bin"]
            downloaded = False
            
            for file in files:
                try:
                    hf_hub_download(
                        repo_id=model_id,
                        filename=file,
                        cache_dir=cache_dir,
                        resume_download=True
                    )
                    downloaded = True
                    break
                except Exception:
                    continue
                    
            if not downloaded:
                # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                snapshot_download(
                    repo_id=model_id,
                    cache_dir=cache_dir,
                    resume_download=True,
                    ignore_patterns=["*.msgpack", "*.h5", "*.ot"]
                )
                
        elif model_type == "unet":
            # UNetãƒ¢ãƒ‡ãƒ«ã®ã¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            print("ğŸ”½ UNetãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
            snapshot_download(
                repo_id=model_id,
                cache_dir=cache_dir,
                resume_download=True,
                ignore_patterns=["*.msgpack", "*.h5", "*.ot", "vae/*", "text_encoder/*", "tokenizer/*"]
            )
            
        else:
            # ãƒ•ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            print("ğŸ”½ ãƒ•ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
            # SD1.5ã‹SDXLã‹ã‚’åˆ¤å®š
            variant = "fp16" if torch.cuda.is_available() or torch.backends.mps.is_available() else None
            
            snapshot_download(
                repo_id=model_id,
                cache_dir=cache_dir,
                resume_download=True,
                variant=variant,
                ignore_patterns=["*.msgpack", "*.h5", "*.ot"]
            )
        
        print(f"âœ… {model_name} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        return True
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {model_name} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
        print(f"   è©³ç´°: {str(e)}")
        return False

def main():
    print("ğŸ¨ Pixa - AIãƒ”ã‚¯ã‚»ãƒ«ã‚¢ãƒ¼ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼")
    print("ğŸ“¥ å¿…è¦ãªãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™\n")
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª
    cache_dir = get_cache_dir()
    print(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å…ˆ: {cache_dir}")
    
    # åˆè¨ˆã‚µã‚¤ã‚ºã®æ¦‚ç®—
    print(f"\nâš ï¸  æ³¨æ„: å…¨ãƒ¢ãƒ‡ãƒ«ã§ç´„25GBå¿…è¦ã§ã™")
    print("   æ—¢ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™")
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¢ºèª
    response = input("\nç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ [Y/n]: ").strip().lower()
    if response == 'n':
        print("âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
        return
    
    # é¸æŠçš„ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    print("\nğŸ“‹ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„:")
    print("   1. å¿…é ˆãƒ¢ãƒ‡ãƒ«ã®ã¿ï¼ˆSD1.5 + All-In-Oneï¼‰ç´„6GB")
    print("   2. æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ï¼ˆä¸Šè¨˜ + LoRAï¼‰ç´„7GB") 
    print("   3. å…¨ãƒ¢ãƒ‡ãƒ« ç´„25GB")
    print("   4. ã‚«ã‚¹ã‚¿ãƒ é¸æŠ")
    
    choice = input("\né¸æŠ [1-4]: ").strip()
    
    models_to_download = []
    
    if choice == "1":
        # å¿…é ˆãƒ¢ãƒ‡ãƒ«ã®ã¿
        models_to_download = [m for m in MODELS_TO_DOWNLOAD if m["id"] in [
            "runwayml/stable-diffusion-v1-5",
            "PublicPrompts/All-In-One-Pixel-Model"
        ]]
    elif choice == "2":
        # æ¨å¥¨ãƒ¢ãƒ‡ãƒ«
        models_to_download = [m for m in MODELS_TO_DOWNLOAD if m["id"] in [
            "runwayml/stable-diffusion-v1-5",
            "PublicPrompts/All-In-One-Pixel-Model",
            "stabilityai/stable-diffusion-xl-base-1.0",
            "nerijs/pixel-art-xl",
            "latent-consistency/lcm-lora-sdxl"
        ]]
    elif choice == "3":
        # å…¨ãƒ¢ãƒ‡ãƒ«
        models_to_download = MODELS_TO_DOWNLOAD
    elif choice == "4":
        # ã‚«ã‚¹ã‚¿ãƒ é¸æŠ
        print("\nãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰:")
        for i, model in enumerate(MODELS_TO_DOWNLOAD):
            print(f"  {i+1}. {model['name']} ({model['size']})")
        
        selections = input("\nç•ªå·ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ› (ä¾‹: 1,2,5): ").strip()
        try:
            indices = [int(x.strip())-1 for x in selections.split(",")]
            models_to_download = [MODELS_TO_DOWNLOAD[i] for i in indices if 0 <= i < len(MODELS_TO_DOWNLOAD)]
        except:
            print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")
            return
    else:
        print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")
        return
    
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
    success_count = 0
    fail_count = 0
    
    for model in models_to_download:
        if download_model(model):
            success_count += 1
        else:
            fail_count += 1
    
    # çµæœè¡¨ç¤º
    print(f"\n{'='*60}")
    print(f"ğŸ“Š ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœ:")
    print(f"   âœ… æˆåŠŸ: {success_count} ãƒ¢ãƒ‡ãƒ«")
    print(f"   âŒ å¤±æ•—: {fail_count} ãƒ¢ãƒ‡ãƒ«")
    print(f"{'='*60}")
    
    if success_count > 0:
        print("\nğŸ‰ ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("   ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¦Pixaã‚’ãŠæ¥½ã—ã¿ãã ã•ã„:")
        print("   $ ./start_server.sh")

if __name__ == "__main__":
    main()
